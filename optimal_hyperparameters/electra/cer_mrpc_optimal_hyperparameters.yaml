lamb: 0.2
lamb_intra: 0.006
learning_rate: 5.0e-05
margin: 0.5
num_train_epochs: 7
objective: 0.871319520174482
per_device_train_batch_size: 16
weight_decay: 0.01
