lamb: 0.02
lamb_intra: 0.005
learning_rate: 1.0e-05
margin: 1.0
num_train_epochs: 15
objective: 0.9364608076009501
per_device_train_batch_size: 64
weight_decay: 0.1
